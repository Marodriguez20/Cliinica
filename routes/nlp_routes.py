from datetime import timedelta
from typing import List, Optional
from fastapi import APIRouter, Depends, HTTPException, Response, Body
from transformers import pipeline, AutoTokenizer, AutoModelForMaskedLM
from textblob import TextBlob
from fastapi.encoders import jsonable_encoder
from fastapi.responses import JSONResponse
from routes.sentimientos_nlp import analisis_sentimientos_nlp
from routes.resumen_nlp import resumen_nlp
from routes.entidad_nlp import entidades_nlp
from routes.traduccion_nlp import traduccion_nlp
from routes.palabras_claves import nlp_palabras_claves
from config.db import SessionLocal, get_db
from modelo.oauth import get_current_user
from models.db_p import Users, Diagnostico, Citas, Entidad, Historial
from sqlalchemy.orm import Session
from modelo import m_pro
from sentence_transformers import SentenceTransformer, util
import torch
import json

#  Router principal NLP
nlp_route = APIRouter(
    prefix="/nlp",
    tags=["NLP"],
    responses={404: {"description": "Not found"}},
)

#  Modelo biom茅dico espa帽ol
tokenizer = AutoTokenizer.from_pretrained("PlanTL-GOB-ES/roberta-base-biomedical-clinical-es")
model = AutoModelForMaskedLM.from_pretrained("PlanTL-GOB-ES/roberta-base-biomedical-clinical-es")
pipe = pipeline("fill-mask", model=model, tokenizer=tokenizer)

# Modelo de embeddings sem谩nticos
modelo_embeddings = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')


@nlp_route.post("/procesar_texto")
async def process_text(
    texto: m_pro.nlp_create = Body(...),
    cita_id: Optional[int] = Body(None),
    db: Session = Depends(get_db),
    current_user: Users = Depends(get_current_user),
):
    try:
        texto_original = texto.texto_original
        resumen = resumen_nlp(texto.texto_original)
        texto_traducido = traduccion_nlp(texto.texto_original)
        entidades = entidades_nlp(texto.texto_original)
        palabras_claves = nlp_palabras_claves(texto.texto_original)
        sentimiento = analisis_sentimientos_nlp(texto.texto_original)

        # Validar cita
        if cita_id:
            cita_existente = db.query(Citas).filter(Citas.id == cita_id).first()
            if not cita_existente:
                cita_id = None

        # Diagn贸stico generado por el modelo biom茅dico
        masked_text = f"El paciente presenta {texto_traducido}. Diagn贸stico probable: <mask>."
        try:
            resultados_mask = pipe(masked_text)
            top_preds = [r["token_str"].strip() for r in resultados_mask[:5]]
            diagnostico_mask = top_preds[0] if top_preds else "Sin diagn贸stico definido"
        except Exception:
            diagnostico_mask = "Sin diagn贸stico definido"
            top_preds = []
        
        # Diagn贸sticos desde BD
        diagnosticos_db = db.query(Diagnostico).all()
        if not diagnosticos_db:
            raise HTTPException(status_code=500, detail="No hay diagn贸sticos en la base de datos.")

        nombres_diagnosticos = [d.diagnostico for d in diagnosticos_db]

        # --- Similitud entre texto original y los diagn贸sticos de BD ---
        emb_texto = modelo_embeddings.encode(texto_original, convert_to_tensor=True)
        emb_diagnosticos = modelo_embeddings.encode(nombres_diagnosticos, convert_to_tensor=True)
        similitudes_texto = util.cos_sim(emb_texto, emb_diagnosticos)[0]

        mejor_idx_texto = torch.argmax(similitudes_texto).item()
        mejor_confianza_texto = similitudes_texto[mejor_idx_texto].item()

        # --- Similitud entre las predicciones del modelo y los diagn贸sticos ---
        mejor_confianza_mask = 0.0
        mejor_idx_mask = -1
        for pred in top_preds:
            emb_pred = modelo_embeddings.encode(pred, convert_to_tensor=True)
            sim_pred = util.cos_sim(emb_pred, emb_diagnosticos)[0]
            idx = torch.argmax(sim_pred).item()
            valor = sim_pred[idx].item()
            if valor > mejor_confianza_mask:
                mejor_confianza_mask = valor
                mejor_idx_mask = idx

        # --- Combinaci贸n ponderada de resultados ---
        peso_texto = 0.7
        peso_mask = 0.3

        if mejor_confianza_texto * peso_texto >= mejor_confianza_mask * peso_mask:
            idx_final = mejor_idx_texto
            confianza_final = mejor_confianza_texto
        else:
            idx_final = mejor_idx_mask
            confianza_final = mejor_confianza_mask

        diag_seleccionado = diagnosticos_db[idx_final]
        diagnostico_final = diag_seleccionado.diagnostico
        diagnostico_id = diag_seleccionado.id

        # Baja confianza
        if confianza_final < 0.40:
            diagnostico_final = "Sin diagn贸stico definido"
            diagnostico_id = None

        # Guardar en historial
        db_item = Historial(
            user_id=current_user.id,
            texto_original=texto_original,
            resumen=resumen,
            traduccion=texto_traducido,
            entidades=json.dumps(entidades, ensure_ascii=False),
            palabras_claves=json.dumps(palabras_claves, ensure_ascii=False),
            sentimiento=json.dumps(sentimiento, ensure_ascii=False),
            diagnosticos_id=diagnostico_id,
            cita_id=cita_id,
        )

        db.add(db_item)
        db.commit()
        db.refresh(db_item)

        return {
            "mensaje": "Diagn贸stico procesado correctamente.",
            "diagnostico_mask": diagnostico_mask,
            "diagnostico_final": diagnostico_final,
            "diagnostico_id": diagnostico_id,
            "confianza": round(confianza_final, 3),
            "predicciones_modelo": top_preds,
            "texto_original": texto_original,
            "resumen": resumen,
            "entidades": entidades,
            "palabras_claves": palabras_claves,
            "sentimiento": sentimiento,
        }

    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"Error al procesar texto: {str(e)}")
